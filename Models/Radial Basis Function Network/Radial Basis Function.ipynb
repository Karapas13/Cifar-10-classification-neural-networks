{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------- Preparing the dataset-----------------------------------------------------------------------------#\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "\n",
    "# Load CIFAR-10 into our programm\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Class labels in CIFAR-10 dataset to make the project more general\n",
    "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Select the two desired classes\n",
    "class_1, class_2 = 3, 5\n",
    "mask_train = (y_train.flatten() == class_1) | (y_train.flatten() == class_2)\n",
    "mask_test = (y_test.flatten() == class_1) | (y_test.flatten() == class_2)\n",
    "\n",
    "x_train, y_train = x_train[mask_train], y_train[mask_train]\n",
    "x_test, y_test = x_test[mask_test], y_test[mask_test]\n",
    "\n",
    "# Relabel classes to 0 and 1 \n",
    "y_train = (y_train.flatten() == class_2).astype(int)\n",
    "y_test = (y_test.flatten() == class_2).astype(int)\n",
    "\n",
    "# Reshaping our dataset\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# Standardize our data \n",
    "scaler = StandardScaler()\n",
    "x_train_flat = scaler.fit_transform(x_train_flat)\n",
    "x_test_flat = scaler.transform(x_test_flat)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.9)\n",
    "x_train_pca = pca.fit_transform(x_train_flat)\n",
    "x_test_pca = pca.transform(x_test_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------- RBF Network (with K-Means)-----------------------------------------------------------------------------#\n",
    "class RBFNN:\n",
    "    def __init__(self, num_centers, spread=None):\n",
    "        self.num_centers = num_centers \n",
    "        self.spread = spread\n",
    "        self.centers = None\n",
    "        self.classifier = None\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        #Choosing centers using Kmeans from scikit learn Library\n",
    "        kmeans = KMeans(n_clusters=self.num_centers, random_state=100) \n",
    "        self.centers = kmeans.fit(x).cluster_centers_ \n",
    "        \n",
    "        # Using RBF transformation for the dataset \n",
    "        rbf_transformed_features = np.exp(-cdist(x, self.centers)  ** 2 / (2 * (self.spread ** 2)))\n",
    "\n",
    "        # Declaring and training our output layer with Logistic Reggression  \n",
    "        self.classifier = LogisticRegression(solver='lbfgs', C = 0.8, max_iter=1500) # max_iter refers to limiting the training interations   \n",
    "        self.classifier.fit(rbf_transformed_features, y)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        rbf_transformed_features = np.exp(-cdist(x, self.centers)  ** 2 / (2 * (self.spread ** 2)))\n",
    "        return self.classifier.predict(rbf_transformed_features)\n",
    "    \n",
    "    \n",
    "\n",
    "# Setting up and testing our RBF model\n",
    "num_centers_list = [10, 100, 500, 1000, 3000, 5000, 8000, 10000] # Choosing the different values of centers number to train our model\n",
    "spreads = [0.1, 1, 10, 50 , 80, 150, 300, 450, 600, 800, 1000, 1200, 1500, 2000]  # Choosing the different number of gaussian function spread to train our model\n",
    "\n",
    "\n",
    "for num_centers in num_centers_list:\n",
    "    print(f\"##################################### centers: {num_centers} #####################################\")\n",
    "    # Declaring arrays for storing accuracies to help us build the plots\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    for spread in spreads:\n",
    "        print(f\"------------------------------- Spread: {spread}-------------------------------\")\n",
    "        start_time = time.time() # Used to calculate execution time\n",
    "\n",
    "        # Initializing our RBF network using the above functions\n",
    "        rbf_net = RBFNN(num_centers=num_centers, spread=spread)\n",
    "        rbf_net.fit(x_train_pca, y_train) \n",
    "\n",
    "        # Making predictions\n",
    "        y_train_pred = rbf_net.predict(x_train_pca)\n",
    "        y_test_pred = rbf_net.predict(x_test_pca)\n",
    "        \n",
    "        # Calculating training and testing accuracy\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)*100 \n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)*100\n",
    "\n",
    "        end_time = time.time() - start_time \n",
    "\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        print(f\"Training time: {end_time:.2f} seconds\")\n",
    "        print(f\"Training accuracy: {train_accuracy:.2f}%\")\n",
    "        print(f\"Testing accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    # Ploting the spread-accuracies plot for the current number of centers \n",
    "    plt.figure()\n",
    "    plt.plot(spreads, train_accuracies, marker='o', label='Training Accuracy') # Ploting the curve for the training  accuracy\n",
    "    plt.plot(spreads, test_accuracies, marker='s', label='Testing Accuracy') # Ploting the curve for the test accuracy\n",
    "    plt.title(f'Accuracy vs Spread for {num_centers} Centers') # Setting the title of the plot\n",
    "    plt.xlabel('Spread') # Setting the label for x-axis\n",
    "    plt.ylabel('Accuracy (%)')  # Setting the label for y-axis\n",
    "    plt.xscale('log')  # Logarithmic scale for x axis - spread representation\n",
    "    plt.ylim(0, 100)  # Accuracy ranges from 0 to 100\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------- RBF Network (with Random Centroids)-----------------------------------------------------------------------------#\n",
    "class RBFNN:\n",
    "    def __init__(self, num_centers, spread=None):\n",
    "        self.num_centers = num_centers \n",
    "        self.spread = spread\n",
    "        self.centers = None\n",
    "        self.classifier = None\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        #Choosing centers using Kmeans from scikit learn Library\n",
    "        random_indices = np.random.choice(x.shape[0], self.num_centers, replace=False)\n",
    "        self.centers = x[random_indices]\n",
    "        \n",
    "        # Using RBF transformation for the dataset \n",
    "        rbf_transformed_features = np.exp(-cdist(x, self.centers)  ** 2 / (2 * (self.spread ** 2)))\n",
    "\n",
    "        # Declaring and training our output layer with Logistic Reggression  \n",
    "        self.classifier = LogisticRegression(solver='lbfgs', C = 0.8, max_iter=1500) # max_iter refers to limiting the training interations   \n",
    "        self.classifier.fit(rbf_transformed_features, y)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        rbf_transformed_features = np.exp(-cdist(x, self.centers)  ** 2 / (2 * (self.spread ** 2)))\n",
    "        return self.classifier.predict(rbf_transformed_features)\n",
    "    \n",
    "    \n",
    "\n",
    "# Setting up and testing our RBF model\n",
    "num_centers_list = [10, 100, 500, 1000, 3000, 5000, 8000, 10000] # Choosing the different values of centers number to train our model\n",
    "spreads = [0.1, 1, 10, 50 , 80, 150, 300, 450, 600, 800, 1000, 1200, 1500, 2000]  # Choosing the different number of gaussian function spread to train our model\n",
    "\n",
    "\n",
    "for num_centers in num_centers_list:\n",
    "    print(f\"##################################### centers: {num_centers} #####################################\")\n",
    "    # Declaring arrays for storing accuracies to help us build the plots\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    for spread in spreads:\n",
    "        print(f\"------------------------------- Spread: {spread}-------------------------------\")\n",
    "        start_time = time.time() # Used to calculate execution time\n",
    "\n",
    "        # Initializing our RBF network using the above functions\n",
    "        rbf_net = RBFNN(num_centers=num_centers, spread=spread)\n",
    "        rbf_net.fit(x_train_pca, y_train) \n",
    "\n",
    "        # Making predictions\n",
    "        y_train_pred = rbf_net.predict(x_train_pca)\n",
    "        y_test_pred = rbf_net.predict(x_test_pca)\n",
    "        \n",
    "        # Calculating training and testing accuracy\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)*100 \n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)*100\n",
    "\n",
    "        end_time = time.time() - start_time \n",
    "\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        print(f\"Training time: {end_time:.2f} seconds\")\n",
    "        print(f\"Training accuracy: {train_accuracy:.2f}%\")\n",
    "        print(f\"Testing accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    # Ploting the spread-accuracies plot for the current number of centers \n",
    "    plt.figure()\n",
    "    plt.plot(spreads, train_accuracies, marker='o', label='Training Accuracy') # Ploting the curve for the training  accuracy\n",
    "    plt.plot(spreads, test_accuracies, marker='s', label='Testing Accuracy') # Ploting the curve for the test accuracy\n",
    "    plt.title(f'Accuracy vs Spread for {num_centers} Centers') # Setting the title of the plot\n",
    "    plt.xlabel('Spread') # Setting the label for x-axis\n",
    "    plt.ylabel('Accuracy (%)')  # Setting the label for y-axis\n",
    "    plt.xscale('log')  # Logarithmic scale for x axis - spread representation\n",
    "    plt.ylim(0, 100)  # Accuracy ranges from 0 to 100\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "    plt.show()\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
